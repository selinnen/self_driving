{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# To complete this homework you just need to correctly finish 5 short functions\n",
    "- [Implementation (Grayscale)](#Implementation-(Grayscale))\n",
    "- [Implementation (Color)](#Implementation-(Color))\n",
    "- [Many Feature Maps](#Many-Feature-Maps)\n",
    "- [Padding](#Padding)\n",
    "- [Stride](#Stride)\n",
    "- [Max-pooling](#Max-pooling)\n",
    "\n",
    "# If your [Summary Test](#Summary-Test) section runs without error, you have finished everything correctly!\n",
    "\n",
    "# Optional resources:\n",
    "Here is a list of a few links that __also__ explain/demo convolutions. You don't have to look at any of them, but if you get stuck they might help you out:\n",
    "\n",
    "Explanation:\n",
    "- http://cs231n.github.io/convolutional-networks/\n",
    "\n",
    "Demos:\n",
    "- http://cs231n.github.io/assets/conv-demo/index.html\n",
    "- http://setosa.io/ev/image-kernels/\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup\n",
    "First we will import our dependencies and load the convolution kernels you've seen in the lecture slides."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# We'll need \"hw.py\" to auto-reload for convenience\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# Load the pre-defined convolution kernels\n",
    "from kernels import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Grayscale\n",
    "Now we will implement grayscale (single channel) convolutions.\n",
    "\n",
    "First, we'll need a way to display, load, and save grayscale images.\n",
    "The following functions do exactly that, as well as normalizing and de-normalizing the images for easier processing (although not entirely required for simple convolutions)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import imshow_grayscale, imload_grayscale, imsave_grayscale"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check that an example image loads and displays correctly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kodim20_grayscale = imload_grayscale('kodim20.png')\n",
    "imshow_grayscale(kodim20_grayscale)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Implementation (Grayscale)\n",
    "Now you will implement single-channel 2D convolutions by filling out the skeleton code for `conv2d_grayscale` in \"hw.py\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hw import conv2d_grayscale\n",
    "%aimport hw"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Sanity Check (Grayscale)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make sure the size of the feature map makes sense for a 3x3 kernel:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_grayscale_size = conv2d_grayscale(kodim20_grayscale, kernel_emboss)\n",
    "assert test_grayscale_size.shape == (kodim20_grayscale.shape[0]-2, kodim20_grayscale.shape[1]-2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and a 5x5 kernel:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_grayscale_size = conv2d_grayscale(kodim20_grayscale, kernel_gauss5)\n",
    "assert test_grayscale_size.shape == (kodim20_grayscale.shape[0]-4, kodim20_grayscale.shape[1]-4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make sure the convolution works with non-square kernels:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel_test_aspect = np.array([\n",
    "    [-1.,  1.,  0., -1.,  1.],\n",
    "    [ 1.,  0.,  0.,  0., -1.],\n",
    "    [-1., -1.,  0.,  1.,  1.]\n",
    "])\n",
    "test_grayscale_aspect = conv2d_grayscale(kodim20_grayscale, kernel_test_aspect)\n",
    "assert test_grayscale_aspect.shape == (kodim20_grayscale.shape[0]-2, kodim20_grayscale.shape[1]-4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Manual testing (Grayscale)\n",
    "To further test your convolution implementation, try running it with some of the kernels defined at the top of this notebook. Compare with the images in the \"out/\" directory to see if you are getting the right results. Also feel free to `imload_grayscale` and use any of your own images! or define your own custom kernels.\n",
    "\n",
    "Use `imshow_grayscale` to display the image. Note: Using matplotlib directly instead might lead to the colors being inaccurate.\n",
    "\n",
    "## [See also: Pro tips](#Pro-Tips)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "test_grayscale = conv2d_grayscale(kodim20_grayscale, kernel_emboss)\n",
    "imshow_grayscale(test_grayscale)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Reference image for kernel_emboss (the default example):__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imshow_grayscale(imload_grayscale('out/emboss.png'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`imshow_grayscale` only shows a small preview of the image.\n",
    "\n",
    "You can use `imsave_grayscale` to save your output to a `.png` file\n",
    "to see it in all its glory:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imsave_grayscale(test_grayscale, 'conv_grayscale.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Color\n",
    "Now we will start working with color images (with three RGB channels).\n",
    "\n",
    "First we need versions of `imshow_grayscale`, `imload_grayscale` and `imsave_grayscale` that can work with color data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import imshow, imload, imsave"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check that an example image loads and displays correctly:\n",
    "\n",
    "The output image should be __in color__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "kodim20 = imload('kodim20.png')\n",
    "imshow(kodim20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Implementation (Color)\n",
    "Now you will implement multi-channel 2D convolutions by filling out the skeleton code for `conv2d` in \"hw.py\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hw import conv2d\n",
    "%aimport hw"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Kernel Stacking\n",
    "To use our single-channel kernels with multi-channel images, we can just stack them in the channel dimension.\n",
    "\n",
    "We divide by the number of channels here so that the kernels don't end up making the image brighter or darker. The idea is that the total \"energy\" of the kernel (sum of all of its elements) must add up to 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stack_kernel(ker, channels=3):\n",
    "    return np.stack([ker] * channels, axis = 2) / channels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By the way, feel free to use different kernels at different channels. In fact, stacking the same kernel multiple times is almost never useful. Convolutional Neural Networks certainly don't do this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# e.g.\n",
    "stacked_combo = np.stack([kernel_gauss3, kernel_laplace, kernel_emboss], axis=2) / 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sanity Check (Color)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make sure the size of the feature map makes sense for a 3x3 kernel:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_size = conv2d(kodim20, stacked_combo)\n",
    "assert test_size.shape == (kodim20.shape[0]-2, kodim20.shape[1]-2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and a 5x5 kernel:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_size = conv2d(kodim20, stack_kernel(kernel_gauss5))\n",
    "assert test_size.shape == (kodim20.shape[0]-4, kodim20.shape[1]-4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make sure the convolution works with non-square kernels:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel_test_aspect = np.array([\n",
    "    [-1.,  1.,  0., -1.,  1.],\n",
    "    [ 1.,  0.,  0.,  0., -1.],\n",
    "    [-1., -1.,  0.,  1.,  1.]\n",
    "])\n",
    "test_aspect = conv2d(kodim20, stack_kernel(kernel_test_aspect))\n",
    "assert test_aspect.shape == (kodim20.shape[0]-2, kodim20.shape[1]-4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Manual testing (Color)\n",
    "Now let's do some manual tests again.\n",
    "\n",
    "Check \"out/r_gauss3-g_laplace-b_emboss.png\" for an example of using `stacked_combo` from above.\n",
    "\n",
    "Somewhat counterintuitively, we still use `imshow_grayscale` to display the feature maps since the convolution still has only a single channel in its output.\n",
    "\n",
    "You can use `stack_kernel` from above for your tests, define a mixed kernel like `stacked_combo` or even roll your own properly 3D kernel. For example, you could try to come up with the real 3D Gaussian blur kernel (it's not just the stacked version we were using above!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = conv2d(kodim20, stacked_combo)\n",
    "imshow_grayscale(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Reference image for r_gauss3-g_laplace-b_emboss (the default example):__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imshow_grayscale(imload_grayscale('out/r_gauss3-g_laplace-b_emboss.png'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can save the images like before:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imsave_grayscale(test, 'conv.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Many Feature Maps\n",
    "Now, with a small adjustment, we will add support for feature maps with multiple channels.\n",
    "\n",
    "Fill out the skeleton code for `conv2d_many` in \"hw.py\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hw import conv2d_many\n",
    "%aimport hw"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Sanity Check (Many)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test that the convolution outputs a multi-channel feature map:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_many = conv2d_many(kodim20, [stack_kernel(kernel_gauss3), stack_kernel(kernel_laplace), stacked_combo])\n",
    "assert(test_many.shape == (kodim20.shape[0]-2, kodim20.shape[1]-2, 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check that `conv2d_many` works with a number of output channels different from the number of input channels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_many = conv2d_many(kodim20, [stack_kernel(kernel_gauss3), stacked_combo])\n",
    "assert(test_many.shape == (kodim20.shape[0]-2, kodim20.shape[1]-2, 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Manual Testing (Many)\n",
    "You can manually test as usual, except that this time you can specify multiple multi-channel kernels to produce a multi-channel color map. Also, now we actually use the color `imshow` and `imsave` since the output finally has multiple channels!\n",
    "\n",
    "Note: using more than 3 kernels will make the feature map too big to be displayed as an image. This is a valid result, since the images we get from most of the feature maps are actually just silly visualizations without much meaning in general.\n",
    "\n",
    "You can check \"out/many.png\" for an example output of using `[stack_kernel(kernel_gauss3), stack_kernel(kernel_laplace), stacked_combo]` as the kernels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test_many = conv2d_many(kodim20, [stack_kernel(kernel_gauss3), stack_kernel(kernel_laplace), stacked_combo])\n",
    "imshow(test_many)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Reference image for the default example:__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imshow(imload('out/many.png'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can save the image as usual:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imsave(test_many, 'conv_many.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Duckietown Instructions\n",
    "This section explains how to play with convolutions from within duckietown.\n",
    "\n",
    "When running `simulator.py` you can specify `--mode=vision` to enable a bunch of computer vision-related features.\n",
    "\n",
    "For this homework, the main feature of interest is the convolution view. Pressing the `N` key cycles between applying preset convolutions (defined in `vision/preset_convs.py`) in real-time! You can drive the car around and see the world as a convolution layer does! You can also toggle grayscale display by pressing the `G` key.\n",
    "\n",
    "Feel free to add your favorite kernels to `vision/preset_convs.py` to see them in duckietown!\n",
    "\n",
    "## Full Vision Mode Controls Reference\n",
    "- `N` - next convolution\n",
    "- `G` - toggle grayscale output\n",
    "- `ENTER` - save screenshot as `screen.npy` and `screen.png`\n",
    "- `P` - toggle semantic segmentation output (ground truth)\n",
    "- `M` - toggle map mode (different version of semantic segmentation that hides all objects and uses different colors)\n",
    "- `T` - toggle top-down view"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Padding\n",
    "The next two sections deal with some features needed for using convolutions in deep learning systems that we are currently missing. They are all very small modifications to the code we already have to make it more powerful.\n",
    "\n",
    "The first is padding. As mentioned during lecture, the size of the feature map is less than the size of the input image. This is very inconvenient for ML system design, so we implement \"padding\" for our convolutions. Basically, we pretend our image is bigger than it is by extending it with zeros before doing the convolution. There are other ways to pad an image that are used in practice but they are simple enough that you can learn about them as you come across them.\n",
    "\n",
    "Fill out the skeleton code for `conv2d_padding` in \"hw.py\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hw import conv2d_padding\n",
    "%aimport hw"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Sanity Check (Padding)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The size should be exactly the same after the convolution as before the convolution:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_padding = conv2d_padding(kodim20, [stack_kernel(kernel_gauss3), stack_kernel(kernel_laplace), stacked_combo])\n",
    "assert test_padding.shape == kodim20.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Manual Testing (Padding)\n",
    "This is pretty boring since the image is only different by a few border pixels on the border.\n",
    "\n",
    "You might want to look at the shape though. Especially versus the output of `conv2d_many`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test_padding = conv2d_padding(kodim20, [stack_kernel(kernel_gauss3), stack_kernel(kernel_laplace), stacked_combo])\n",
    "imshow(test_padding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_many = conv2d_many(kodim20, [stack_kernel(kernel_gauss3), stack_kernel(kernel_laplace), stacked_combo])\n",
    "print(test_many.shape, test_padding.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can save the image as usual:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imsave(test_padding, 'out/padding.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Stride\n",
    "The other feature that our convolutions are missing is called \"stride\".\n",
    "\n",
    "Stride is the number of pixels by which the kernel moves each time it takes a step across the image. Our current implementation can actually be said to use stride of 1, since we always move the kernel by just one pixel. In practice, sometimes we want to skip half of the valid kernel positions (use stride = 2) to \"downsample\" the image. This means that we force the model to remove half of the information from the image, and come up with a way to summarize it in fewer pixels. This heavily speeds up computer vision models, and is useful for putting some pressure on the network to come up with creative convolutions.\n",
    "\n",
    "Fill out `conv2d_full` in \"hw.py\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hw import conv2d_full\n",
    "%aimport hw"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Sanity check (Stride)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The output with stride = 2 should be exactly half the size off the input image (since we used padding):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_stride = conv2d_full(kodim20, [stack_kernel(kernel_gauss3), stack_kernel(kernel_laplace), stacked_combo], stride=2)\n",
    "assert test_stride.shape == (kodim20.shape[0]//2, kodim20.shape[1]//2, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Manual Testing (Stride)\n",
    "We can run this convolution version the same way as `conv2d_many`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test_stride = conv2d_full(kodim20, [stack_kernel(kernel_gauss3), stack_kernel(kernel_laplace), stacked_combo], stride=2)\n",
    "imshow(test_stride)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is pretty boring, since matplotlib resizes all images to the same dimensions, so we compare the shape of this output to the shape of the stride = 1 output:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_stride1 = conv2d_full(kodim20, [stack_kernel(kernel_gauss3), stack_kernel(kernel_laplace), stacked_combo], stride=1)\n",
    "print(test_stride.shape, test_stride1.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you save the image as a file, you can see the fact that the size is about half of a normal output yourself.\n",
    "\n",
    "You can save the image as usual:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imsave(test_stride, 'conv_full.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Max-pooling\n",
    "Max-pooling is another way of downsampling an image. Pooling is somewhat controversial but it appears so often in practice that you should really know about it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hw import maxpool2d\n",
    "%aimport hw"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Sanity Check (Max-pooling)\n",
    "Check that the maxpool output is exactly one third of the input:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_maxpool = maxpool2d(kodim20)\n",
    "assert test_maxpool.shape == (kodim20.shape[0]//3, kodim20.shape[1]//3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Manual Testing (Max-pooling)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Max-pooled images look very interesting, but the change is only very obvious if you use a large pooling window.\n",
    "\n",
    "Try setting size = 11 (and stride = 11) as an example.\n",
    "\n",
    "Keeping stride and size equal is generally a good idea for some information theory reasons (since otherwise the pooling windows overlap).\n",
    "\n",
    "Note: size must be odd for padding to work correctly, because we pad both sides the same amount. Real ML frameworks just stick the extra padding on some pre-determined side of the image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "test_maxpool = maxpool2d(kodim20, size=11, stride=11)\n",
    "imshow_grayscale(test_maxpool)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you save the image as a file, you can see that it is a lot smaller than the input.\n",
    "\n",
    "You can save the image as usual:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imsave_grayscale(test_maxpool, 'maxpool.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Summary Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grayscale\n",
    "test_grayscale_size = conv2d_grayscale(kodim20_grayscale, kernel_emboss)\n",
    "assert test_grayscale_size.shape == (kodim20_grayscale.shape[0]-2, kodim20_grayscale.shape[1]-2)\n",
    "\n",
    "test_grayscale_size = conv2d_grayscale(kodim20_grayscale, kernel_gauss5)\n",
    "assert test_grayscale_size.shape == (kodim20_grayscale.shape[0]-4, kodim20_grayscale.shape[1]-4)\n",
    "\n",
    "kernel_test_aspect = np.array([\n",
    "    [-1.,  1.,  0., -1.,  1.],\n",
    "    [ 1.,  0.,  0.,  0., -1.],\n",
    "    [-1., -1.,  0.,  1.,  1.]\n",
    "])\n",
    "test_grayscale_aspect = conv2d_grayscale(kodim20_grayscale, kernel_test_aspect)\n",
    "assert test_grayscale_aspect.shape == (kodim20_grayscale.shape[0]-2, kodim20_grayscale.shape[1]-4)\n",
    "\n",
    "# Color\n",
    "test_size = conv2d(kodim20, stacked_combo)\n",
    "assert test_size.shape == (kodim20.shape[0]-2, kodim20.shape[1]-2)\n",
    "\n",
    "test_size = conv2d(kodim20, stack_kernel(kernel_gauss5))\n",
    "assert test_size.shape == (kodim20.shape[0]-4, kodim20.shape[1]-4)\n",
    "\n",
    "kernel_test_aspect = np.array([\n",
    "    [-1.,  1.,  0., -1.,  1.],\n",
    "    [ 1.,  0.,  0.,  0., -1.],\n",
    "    [-1., -1.,  0.,  1.,  1.]\n",
    "])\n",
    "test_aspect = conv2d(kodim20, stack_kernel(kernel_test_aspect))\n",
    "assert test_aspect.shape == (kodim20.shape[0]-2, kodim20.shape[1]-4)\n",
    "\n",
    "# Many\n",
    "test_many = conv2d_many(kodim20, [stack_kernel(kernel_gauss3), stack_kernel(kernel_laplace), stacked_combo])\n",
    "assert(test_many.shape == (kodim20.shape[0]-2, kodim20.shape[1]-2, 3))\n",
    "\n",
    "test_many = conv2d_many(kodim20, [stack_kernel(kernel_gauss3), stacked_combo])\n",
    "assert(test_many.shape == (kodim20.shape[0]-2, kodim20.shape[1]-2, 2))\n",
    "\n",
    "# Padding\n",
    "test_padding = conv2d_padding(kodim20, [stack_kernel(kernel_gauss3), stack_kernel(kernel_laplace), stacked_combo])\n",
    "assert test_padding.shape == kodim20.shape\n",
    "\n",
    "# Stride\n",
    "test_stride = conv2d_full(kodim20, [stack_kernel(kernel_gauss3), stack_kernel(kernel_laplace), stacked_combo], stride=2)\n",
    "assert test_stride.shape == (kodim20.shape[0]//2, kodim20.shape[1]//2, 3)\n",
    "\n",
    "# Maxpool\n",
    "test_maxpool = maxpool2d(kodim20)\n",
    "assert test_maxpool.shape == (kodim20.shape[0]//3, kodim20.shape[1]//3)\n",
    "\n",
    "print('Sanity checks passed! Now run the 2 cells below!!!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combined\n",
    "test_combined = conv2d_full(kodim20, [stack_kernel(kernel_gauss3), stack_kernel(kernel_laplace), stacked_combo], stride=3)\n",
    "test_combined = maxpool2d(test_combined, size=5, stride=5)\n",
    "test_combined = conv2d_grayscale(test_combined, kernel_laplace)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct_out = imload_grayscale('out/combined.png')\n",
    "\n",
    "imshow_grayscale(test_combined)\n",
    "imshow_grayscale(correct_out)\n",
    "\n",
    "imshow_grayscale(correct_out - test_combined.clip(0, 1))\n",
    "\n",
    "err = correct_out - test_combined.clip(0, 1)\n",
    "mse = np.sum(err * err)\n",
    "print(mse)\n",
    "\n",
    "assert mse < .01\n",
    "\n",
    "print('All good! You are ready for checkoff!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Pro Tips\n",
    "## Edge Detection & Blur\n",
    "if using any of the \"edge detection\" kernels (`lsobel`, `lscharr`, `lprewitt`, `laplace`), you might get better results by first blurring the image with e.g. `gauss5`.\n",
    "\n",
    "Example:\n",
    "```python\n",
    "test_grayscale = conv2d_grayscale(kodim20_grayscale, kernel_gauss5)\n",
    "test_grayscale = conv2d_grayscale(test_grayscale, kernel_lsobel)\n",
    "imshow_grayscale(test_grayscale)\n",
    "```\n",
    "\n",
    "\n",
    "## Custom kernels\n",
    "if you invent a kernel and the image is too bright or too dark (or completely white or black), make sure all the numbers in the kernel sum up to 1, otherwise it will make the image darker or brighter by some amount."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
